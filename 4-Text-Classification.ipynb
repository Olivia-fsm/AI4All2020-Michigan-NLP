{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Save2Drive](https://raw.githubusercontent.com/alahnala/AI4All2020-Michigan-NLP/master/slides/save2drive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a copy of the [Documentation Template](https://docs.google.com/presentation/d/1zA1saxePvvjW_ZNA49L8U5Gh5yk6HmqHrcYjKokHcdQ/edit?usp=sharing) in your Drive for documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the cell below to get setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "  !rm -r AI4All2020-Michigan-NLP\n",
    "  !git clone https://github.com/alahnala/AI4All2020-Michigan-NLP.git\n",
    "  !cp -r AI4All2020-Michigan-NLP/utils/ .\n",
    "  !cp -r AI4All2020-Michigan-NLP/Data/ .\n",
    "  !cp -r AI4All2020-Michigan-NLP/slides/ .\n",
    "  !cp -r AI4All2020-Michigan-NLP/Experiment-Report-Templates/ .\n",
    "  !echo \"=== Files Copied ===\"\n",
    "from utils.classification_helpers import *\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from utils.nlp_basics import *\n",
    "from utils.syllable import *\n",
    "\n",
    "\n",
    "# general\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# preprocess functions\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine if text is part of ingredients or procedure\n",
    "\n",
    "There are so many recipes on the internet!! Wouldn't it be great if you could find new recipes based on your favorite ingredients or the ingredients you have available in your house? \n",
    "\n",
    "One challenge of this would be the fact that recipes posted on the internet can be formatted in very different ways. This could make information retrieval quite challenging.\n",
    "\n",
    "In this part of the project, we will create a system that can tell us if a section of text belongs to a list of ingredients or a the cooking procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Observations\n",
    "\n",
    "1. From utils.classification_helpers, we imported two data structures for you: `Ingredients` and `Procedures`\n",
    "2. These are both lists of unstructure text from recipes obtained from wikipedia\n",
    "3. Write some code in the cell below to help you get to understand what this data looks like.\n",
    "4. Document your observations in the **Data Observations** slide. Keep in mind that you will be building a Decision Tree classifier, so try to specifically note some differences between the Ingredients text and the Procedures text. You can use these differences as “features” for your decision tree classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "How long are our lists of Ingredients and Procedures?\n",
    "'''\n",
    "Ingredients_length = len(Ingredients)\n",
    "Procedures_length = len(Procedures)\n",
    "print(\"Length of Ingredients:\", Ingredients_length, \"Length of Procedure:\", Procedures_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What does the text in Ingredients look like?\n",
    "'''\n",
    "import random\n",
    "print(random.sample(Ingredients, k=2))\n",
    "print(Ingredients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What does the text in Procedures look like?\n",
    "'''\n",
    "import random\n",
    "print(random.sample(Procedures, k=2))\n",
    "print(Procedures[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data\n",
    "\n",
    "- We created a function below called `make_histogram` which you can use to plot histograms of numerical data for the `Ingredients` and `Procedures` side-by-side to observe differences. Run the cell below to load the function.\n",
    "- The following cell shows an example of using the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_histogram(List_of_Values_1, Title_1, X_label_1, List_of_Values_2, Title_2, X_label_2):\n",
    "    %matplotlib inline\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    matplotlib.rcParams.update({\n",
    "        'font.family': 'serif',\n",
    "        'font.size': 20\n",
    "    })\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5), sharey=False)\n",
    "\n",
    "\n",
    "    n, bins, patches = axs[0].hist(x=List_of_Values_1, bins='auto', rwidth=0.9, color='#422e9e')\n",
    "\n",
    "    axs[0].grid(axis='y', alpha=0.7, color='lavender')\n",
    "    axs[0].set_xlabel(X_label_1)\n",
    "    axs[0].set_ylabel('Frequency')\n",
    "    axs[0].set_title(Title_1, pad=20)\n",
    "\n",
    "\n",
    "    n, bins, patches = axs[1].hist(x=List_of_Values_2, bins='auto', rwidth=0.9, color='#422e9e')\n",
    "\n",
    "    axs[1].grid(axis='y', alpha=0.7, color='lavender')\n",
    "    axs[1].set_xlabel(X_label_2)\n",
    "    axs[1].set_ylabel('Frequency')\n",
    "    axs[1].set_title(Title_2, pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Histogram function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical data for ingredients\n",
    "Num_Words_Ingredients = [len(item.split()) for item in Ingredients]\n",
    "\n",
    "# Load numerical data into List_of_Values and create a histogram title and X axis label\n",
    "List_of_Values_1 = Num_Words_Ingredients\n",
    "Title_1 = 'Histogram for Number of Words\\n(Ingredients)'\n",
    "X_label_1 = 'Number of Words per Item'\n",
    "\n",
    "# List of numerical data for Procedures\n",
    "Num_Words_Procedures = [len(item.split()) for item in Procedures]\n",
    "\n",
    "# Load numerical data into List_of_Values and create a histogram title and X axis label\n",
    "List_of_Values_2 = Num_Words_Procedures\n",
    "Title_2 = 'Histogram for Number of Words\\n(Procedures)'\n",
    "X_label_2 = 'Number of Words per Item'\n",
    "\n",
    "# Calls the make_histogram function to make histograms with the information we pass in\n",
    "make_histogram(List_of_Values_1, Title_1, X_label_1, List_of_Values_2, Title_2, X_label_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the cell below to make a list of a different numerical measure for each item in each list to plot in the histograms. Repeat for as many kinda of numeric data you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_Lines_Ingredients = [len(item.split('\\n')) for item in Ingredients]\n",
    "Num_Lines_Procedures = [len(item.split('\\n')) for item in Procedures]\n",
    "\n",
    "List_of_Values_1 = Num_Lines_Ingredients\n",
    "Title_1 = 'Histogram for Number of Lines\\n(Ingredients)'\n",
    "X_label_1 = 'Number of Lines per Item'\n",
    "\n",
    "List_of_Values_2 = Num_Lines_Procedures\n",
    "Title_2 = 'Histogram for Number of Lines\\n(Procedures)'\n",
    "X_label_2 = 'Number of Lines per Item'\n",
    "make_histogram(List_of_Values_1, Title_1, X_label_1, List_of_Values_2, Title_2, X_label_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation - paste your histograms in your slides, under the **Data Observations - Numerical** (create copies of the slide if you have multiple histograms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decision Tree\n",
    "\n",
    "- Implement the function `simple_decision_tree` with one rule based on your data observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_decision_tree(item):\n",
    "    num_words = len(item.split())\n",
    "    if num_words > 60:\n",
    "        decision = 'Procedure'\n",
    "    else:\n",
    "        decision = 'Ingredients'\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Ingredients\n",
    "\n",
    "- Run the cell below to use you `simple_decision_tree` function on all of the ingredient items.\n",
    "- The cell will count the number of correct decisions by your simple decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This for-loop will run the simple decision tree on each item of the Ingredients list \n",
    "ingredient_classifications = []\n",
    "for item in Ingredients:\n",
    "    decision = simple_decision_tree(item)\n",
    "    ingredient_classifications.append(decision)\n",
    "    \n",
    "# Counter will count the number of times each unique item shows up in the list\n",
    "ingredient_decision_counts = Counter(ingredient_classifications)\n",
    "\n",
    "# This gets the number of times 'Ingredients' was decided\n",
    "ingredients_correct = ingredient_decision_counts['Ingredients']\n",
    "\n",
    "# Get the total number of items\n",
    "total_ingredients = len(ingredient_classifications)\n",
    "\n",
    "# Output the result\n",
    "print(\"Number of Correct Decisions for Ingredients:\", ingredients_correct, 'out of', total_ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Procedures\n",
    "\n",
    "- Run the cell below to use you `simple_decision_tree` function on all of the Procedures items.\n",
    "- The cell will count the number of correct decisions by your simple decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This for-loop will run the simple decision tree on each item of the Procedures list \n",
    "procedure_classifications = []\n",
    "for item in Procedures:\n",
    "    decision = simple_decision_tree(item)\n",
    "    procedure_classifications.append(decision)\n",
    "    \n",
    "# Counter will count the number of times each unique item shows up in the list\n",
    "procedure_decision_counts = Counter(procedure_classifications)\n",
    "\n",
    "# This gets the number of times 'Procedure' was decided\n",
    "procedures_correct = procedure_decision_counts['Procedure']\n",
    "\n",
    "# Get the total number of items\n",
    "total_procedures = len(procedure_classifications)\n",
    "\n",
    "# Output the result\n",
    "print(\"Number of Correct Decisions for Procedures:\", procedures_correct, 'out of', total_procedures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Simple Decision Tree Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(actual, predicted):\n",
    "    total_correct = len([1 for a,p in zip(actual, predicted) if a == p])\n",
    "    total = len(actual)\n",
    "    \n",
    "    accuracy = total_correct / total\n",
    "    return accuracy\n",
    "\n",
    "actual = ['Ingredients'] * len(ingredient_classifications) + ['Procedure'] * len(procedure_classifications)\n",
    "predicted = ingredient_classifications + procedure_classifications\n",
    "\n",
    "accuracy = get_accuracy(actual, predicted)\n",
    "\n",
    "print(\"Simple Decision Tree Accuracy: {:.2%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_vs_predicted(actual, predicted):\n",
    "    classes = Counter(actual).keys()\n",
    "    co_occurrence_matrix =  np.zeros((len(classes), len(classes)))\n",
    "    \n",
    "    class_idx = {class_:i for i, class_ in enumerate(classes)}\n",
    "    for actual_class, predicted_class in zip(actual, predicted):\n",
    "        i = class_idx[actual_class]\n",
    "        j = class_idx[predicted_class]\n",
    "        co_occurrence_matrix[i][j] += 1\n",
    "\n",
    "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
    "\n",
    "\n",
    "    make_heatmap(co_occurrence_matrix, rows=class_idx, cols=class_idx, annotate=True, xlabel='Predicted', ylabel='Actual', figsize=(12,8))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "actual_vs_predicted(actual, predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text to help interpret confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_vs_predicted_text(actual, predicted):\n",
    "\n",
    "    classes = Counter(actual).keys()\n",
    "    co_occurrence_matrix =  np.zeros((len(classes), len(classes)))\n",
    "    \n",
    "    class_idx = {class_:i for i, class_ in enumerate(classes)}\n",
    "    idx2class = {i:class_ for i, class_ in enumerate(classes)}\n",
    "    \n",
    "    for actual_class, predicted_class in zip(actual, predicted):\n",
    "        i = class_idx[actual_class]\n",
    "        j = class_idx[predicted_class]\n",
    "        co_occurrence_matrix[i][j] += 1\n",
    "    \n",
    "    for class_1 in classes:\n",
    "        for class_2 in classes:\n",
    "            i = class_idx[class_1]\n",
    "            j = class_idx[class_2]\n",
    "            num = co_occurrence_matrix[i][j]\n",
    "            print(\"{}\\t{} items were classified as {}\".format(int(num), class_1, class_2))\n",
    "\n",
    "    return\n",
    "actual_vs_predicted_text(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "\n",
    "- Write a function to preprocess the data into lists of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(text_line):\n",
    "    \n",
    "    text_line = text_line.split('\\n')\n",
    "    text_line = ' '.join(text_line)\n",
    "    tokens = word_tokenize(text_line)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "test_string = Ingredients[0]\n",
    "print(\"Test string\", test_string)\n",
    "preprocessed_test_string = preprocess_line(test_string)\n",
    "print(\"Test string preprocessed tokens\", preprocessed_test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
