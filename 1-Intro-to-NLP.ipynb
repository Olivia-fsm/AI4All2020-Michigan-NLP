{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.nlp_basics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "1. Tokenization\n",
    "2. Lemmatization\n",
    "3. Stemming\n",
    "4. Part-of-speech tagging\n",
    "5. Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tokenization](./slides/tokenization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's play with the string sequence `cake_wikipedia`\n",
    "\n",
    "## 1. Simplest tokenizer: split on spaces\n",
    "\n",
    "Run the cell below. Here we split the sequence by spaces. How would you describe these tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <td>Cake</td>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "      <td>form</td>\n",
       "      <td>of</td>\n",
       "      <td>sweet</td>\n",
       "      <td>food</td>\n",
       "      <td>made</td>\n",
       "      <td>from</td>\n",
       "      <td>flour,</td>\n",
       "      <td>sugar,</td>\n",
       "      <td>and</td>\n",
       "      <td>other</td>\n",
       "      <td>ingredients,</td>\n",
       "      <td>that</td>\n",
       "      <td>is</td>\n",
       "      <td>usually</td>\n",
       "      <td>baked.</td>\n",
       "      <td>In</td>\n",
       "      <td>their</td>\n",
       "      <td>oldest</td>\n",
       "      <td>forms,</td>\n",
       "      <td>cakes</td>\n",
       "      <td>were</td>\n",
       "      <td>modifications</td>\n",
       "      <td>of</td>\n",
       "      <td>bread,</td>\n",
       "      <td>but</td>\n",
       "      <td>cakes</td>\n",
       "      <td>now</td>\n",
       "      <td>cover</td>\n",
       "      <td>a</td>\n",
       "      <td>wide</td>\n",
       "      <td>range</td>\n",
       "      <td>of</td>\n",
       "      <td>preparations</td>\n",
       "      <td>that</td>\n",
       "      <td>can</td>\n",
       "      <td>be</td>\n",
       "      <td>simple</td>\n",
       "      <td>or</td>\n",
       "      <td>elaborate,</td>\n",
       "      <td>and</td>\n",
       "      <td>that</td>\n",
       "      <td>share</td>\n",
       "      <td>features</td>\n",
       "      <td>with</td>\n",
       "      <td>other</td>\n",
       "      <td>desserts</td>\n",
       "      <td>such</td>\n",
       "      <td>as</td>\n",
       "      <td>pastries,</td>\n",
       "      <td>meringues,</td>\n",
       "      <td>custards,</td>\n",
       "      <td>and</td>\n",
       "      <td>pies.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1  2     3   4      5     6     7     8       9       10   11  \\\n",
       "Text  Cake  is  a  form  of  sweet  food  made  from  flour,  sugar,  and   \n",
       "\n",
       "         12            13    14  15       16      17  18     19      20  \\\n",
       "Text  other  ingredients,  that  is  usually  baked.  In  their  oldest   \n",
       "\n",
       "          21     22    23             24  25      26   27     28   29     30  \\\n",
       "Text  forms,  cakes  were  modifications  of  bread,  but  cakes  now  cover   \n",
       "\n",
       "     31    32     33  34            35    36   37  38      39  40          41  \\\n",
       "Text  a  wide  range  of  preparations  that  can  be  simple  or  elaborate,   \n",
       "\n",
       "       42    43     44        45    46     47        48    49  50         51  \\\n",
       "Text  and  that  share  features  with  other  desserts  such  as  pastries,   \n",
       "\n",
       "              52         53   54     55  \n",
       "Text  meringues,  custards,  and  pies.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first few sentences from the wikipedia page on Cake https://en.wikipedia.org/wiki/Cake\n",
    "cake_wikipedia = 'Cake is a form of sweet food made from flour, sugar, and other ingredients, that is usually baked. In their oldest forms, cakes were modifications of bread, but cakes now cover a wide range of preparations that can be simple or elaborate, and that share features with other desserts such as pastries, meringues, custards, and pies.'\n",
    "\n",
    "# calling .split() on a string will split the string on spaces\n",
    "tokens = cake_wikipedia.split()\n",
    "show_tokens(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split on spaces and separate punctuation from words.\n",
    "\n",
    "Run the cell below. How would you describe these tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <td>Cake</td>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "      <td>form</td>\n",
       "      <td>of</td>\n",
       "      <td>sweet</td>\n",
       "      <td>food</td>\n",
       "      <td>made</td>\n",
       "      <td>from</td>\n",
       "      <td>flour</td>\n",
       "      <td>,</td>\n",
       "      <td>sugar</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>other</td>\n",
       "      <td>ingredients</td>\n",
       "      <td>,</td>\n",
       "      <td>that</td>\n",
       "      <td>is</td>\n",
       "      <td>usually</td>\n",
       "      <td>baked</td>\n",
       "      <td>.</td>\n",
       "      <td>In</td>\n",
       "      <td>their</td>\n",
       "      <td>oldest</td>\n",
       "      <td>forms</td>\n",
       "      <td>,</td>\n",
       "      <td>cakes</td>\n",
       "      <td>were</td>\n",
       "      <td>modifications</td>\n",
       "      <td>of</td>\n",
       "      <td>bread</td>\n",
       "      <td>,</td>\n",
       "      <td>but</td>\n",
       "      <td>cakes</td>\n",
       "      <td>now</td>\n",
       "      <td>cover</td>\n",
       "      <td>a</td>\n",
       "      <td>wide</td>\n",
       "      <td>range</td>\n",
       "      <td>of</td>\n",
       "      <td>preparations</td>\n",
       "      <td>that</td>\n",
       "      <td>can</td>\n",
       "      <td>be</td>\n",
       "      <td>simple</td>\n",
       "      <td>or</td>\n",
       "      <td>elaborate</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>that</td>\n",
       "      <td>share</td>\n",
       "      <td>features</td>\n",
       "      <td>with</td>\n",
       "      <td>other</td>\n",
       "      <td>desserts</td>\n",
       "      <td>such</td>\n",
       "      <td>as</td>\n",
       "      <td>pastries</td>\n",
       "      <td>,</td>\n",
       "      <td>meringues</td>\n",
       "      <td>,</td>\n",
       "      <td>custards</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>pies</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1  2     3   4      5     6     7     8      9  10     11 12   13  \\\n",
       "Text  Cake  is  a  form  of  sweet  food  made  from  flour  ,  sugar  ,  and   \n",
       "\n",
       "         14           15 16    17  18       19     20 21  22     23      24  \\\n",
       "Text  other  ingredients  ,  that  is  usually  baked  .  In  their  oldest   \n",
       "\n",
       "         25 26     27    28             29  30     31 32   33     34   35  \\\n",
       "Text  forms  ,  cakes  were  modifications  of  bread  ,  but  cakes  now   \n",
       "\n",
       "         36 37    38     39  40            41    42   43  44      45  46  \\\n",
       "Text  cover  a  wide  range  of  preparations  that  can  be  simple  or   \n",
       "\n",
       "             47 48   49    50     51        52    53     54        55    56  \\\n",
       "Text  elaborate  ,  and  that  share  features  with  other  desserts  such   \n",
       "\n",
       "      57        58 59         60 61        62 63   64    65 66  \n",
       "Text  as  pastries  ,  meringues  ,  custards  ,  and  pies  .  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk is a library that is open for anyone to use. \n",
    "# It stands for \"natural language tool kit\" and has many useful functions\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# We use nltk's function \"word_tokenize\"\n",
    "tokens = word_tokenize(cake_wikipedia)\n",
    "\n",
    "show_tokens(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split on syllables.\n",
    "\n",
    "Run the cell below. How would you describe these tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alcllahn/AI4ALL-NLP/allie-projects/utils/syllable.py:104: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: ' '\n",
      "  \" assigning as vowel: '{}'\".format(c)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <td>Ca</td>\n",
       "      <td>ke</td>\n",
       "      <td>i</td>\n",
       "      <td>s a</td>\n",
       "      <td></td>\n",
       "      <td>for</td>\n",
       "      <td>m o</td>\n",
       "      <td>f</td>\n",
       "      <td>swee</td>\n",
       "      <td>t</td>\n",
       "      <td>foo</td>\n",
       "      <td>d</td>\n",
       "      <td>ma</td>\n",
       "      <td>de</td>\n",
       "      <td>fro</td>\n",
       "      <td>m</td>\n",
       "      <td>flour</td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>su</td>\n",
       "      <td>gar</td>\n",
       "      <td>,</td>\n",
       "      <td>an</td>\n",
       "      <td>d ot</td>\n",
       "      <td>he</td>\n",
       "      <td>r in</td>\n",
       "      <td>gre</td>\n",
       "      <td>dients</td>\n",
       "      <td>,</td>\n",
       "      <td>t</td>\n",
       "      <td>ha</td>\n",
       "      <td>t i</td>\n",
       "      <td>s u</td>\n",
       "      <td>sual</td>\n",
       "      <td>ly</td>\n",
       "      <td>ba</td>\n",
       "      <td>ked</td>\n",
       "      <td>.</td>\n",
       "      <td>I</td>\n",
       "      <td>n t</td>\n",
       "      <td>hei</td>\n",
       "      <td>r ol</td>\n",
       "      <td>des</td>\n",
       "      <td>t</td>\n",
       "      <td>forms</td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>ca</td>\n",
       "      <td>ke</td>\n",
       "      <td>s</td>\n",
       "      <td>we</td>\n",
       "      <td>re</td>\n",
       "      <td>mo</td>\n",
       "      <td>di</td>\n",
       "      <td>fi</td>\n",
       "      <td>ca</td>\n",
       "      <td>tion</td>\n",
       "      <td>s o</td>\n",
       "      <td>f</td>\n",
       "      <td>bread</td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>bu</td>\n",
       "      <td>t</td>\n",
       "      <td>ca</td>\n",
       "      <td>ke</td>\n",
       "      <td>s</td>\n",
       "      <td>no</td>\n",
       "      <td>w</td>\n",
       "      <td>co</td>\n",
       "      <td>ve</td>\n",
       "      <td>r a</td>\n",
       "      <td></td>\n",
       "      <td>wi</td>\n",
       "      <td>de</td>\n",
       "      <td>ran</td>\n",
       "      <td>ge</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>pre</td>\n",
       "      <td>pa</td>\n",
       "      <td>ra</td>\n",
       "      <td>tion</td>\n",
       "      <td>s t</td>\n",
       "      <td>ha</td>\n",
       "      <td>t</td>\n",
       "      <td>ca</td>\n",
       "      <td>n</td>\n",
       "      <td>be</td>\n",
       "      <td>sim</td>\n",
       "      <td>ple</td>\n",
       "      <td>o</td>\n",
       "      <td>r e</td>\n",
       "      <td>la</td>\n",
       "      <td>bo</td>\n",
       "      <td>ra</td>\n",
       "      <td>te</td>\n",
       "      <td>,</td>\n",
       "      <td>an</td>\n",
       "      <td>d t</td>\n",
       "      <td>ha</td>\n",
       "      <td>t s</td>\n",
       "      <td>ha</td>\n",
       "      <td>re</td>\n",
       "      <td>fea</td>\n",
       "      <td>tu</td>\n",
       "      <td>re</td>\n",
       "      <td>s</td>\n",
       "      <td>wit</td>\n",
       "      <td>h ot</td>\n",
       "      <td>he</td>\n",
       "      <td>r</td>\n",
       "      <td>des</td>\n",
       "      <td>ser</td>\n",
       "      <td>ts</td>\n",
       "      <td>suc</td>\n",
       "      <td>h a</td>\n",
       "      <td>s</td>\n",
       "      <td>pas</td>\n",
       "      <td>tries</td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>me</td>\n",
       "      <td>rin</td>\n",
       "      <td>gues</td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>cus</td>\n",
       "      <td>tards</td>\n",
       "      <td>,</td>\n",
       "      <td>an</td>\n",
       "      <td>d</td>\n",
       "      <td>pies.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3   4    5    6   7     8   9    10  11  12   13   14  15   \\\n",
       "Text  Ca  ke    i  s a      for  m o  f   swee  t   foo  d   ma  de   fro  m    \n",
       "\n",
       "        16  17  18  19   20  21   22    23  24    25   26      27  28  29   \\\n",
       "Text  flour   ,      su  gar   ,   an  d ot  he  r in  gre  dients   ,   t   \n",
       "\n",
       "     30   31   32    33   34  35   36  37  38   39   40    41   42  43   \\\n",
       "Text  ha  t i  s u  sual  ly   ba  ked   .   I  n t  hei  r ol  des  t    \n",
       "\n",
       "        44  45  46  47  48  49  50   51  52  53  54  55    56   57  58   \\\n",
       "Text  forms   ,      ca  ke  s   we  re   mo  di  fi  ca  tion  s o  f    \n",
       "\n",
       "        59  60  61  62  63  64  65  66  67  68  69  70   71  72  73   74   \\\n",
       "Text  bread   ,      bu  t   ca  ke  s   no  w   co  ve  r a      wi  de    \n",
       "\n",
       "      75   76  77  78   79  80  81    82   83  84  85  86  87   88   89   \\\n",
       "Text  ran  ge    o  f   pre  pa  ra  tion  s t  ha  t   ca  n   be   sim   \n",
       "\n",
       "       90  91   92  93  94  95  96  97   98   99  100  101 102  103  104 105  \\\n",
       "Text  ple    o  r e  la  bo  ra  te   ,   an  d t  ha  t s  ha  re   fea  tu   \n",
       "\n",
       "     106 107  108   109 110 111  112  113  114  115  116 117  118    119 120  \\\n",
       "Text  re  s   wit  h ot  he  r   des  ser  ts   suc  h a  s   pas  tries   ,   \n",
       "\n",
       "     121 122  123   124 125 126  127    128 129  130 131    132  \n",
       "Text      me  rin  gues   ,      cus  tards   ,   an  d   pies.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.syllable import *\n",
    "\n",
    "syllable_tokenize = SyllableTokenizer()\n",
    "tokens = syllable_tokenize.tokenize(cake_wikipedia)\n",
    "\n",
    "# Show table\n",
    "show_tokens(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Challenge: What are some tokenization considerations to make if you're working with tweets?\n",
    "\n",
    "Try making a tokenizer that keeps hashtags with the # and user handles with the @."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-3a48b57a1af3>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-3a48b57a1af3>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    tokens =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tweet = 'Today, I am learning how to #tokenize with @AI4All!!!!!'\n",
    "\n",
    "def tokenizer(string):\n",
    "    \n",
    "    ## Your code (use as many lines as you like)\n",
    "    tokens = \n",
    "    \n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "tokens = tokenizer(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Would tokenization in English look the same as other languages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "french = \"C'est en effet tout à fait dans la ligne des positions que notre Parlement a toujours adoptées.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <td>C'est</td>\n",
       "      <td>en</td>\n",
       "      <td>effet</td>\n",
       "      <td>tout</td>\n",
       "      <td>à</td>\n",
       "      <td>fait</td>\n",
       "      <td>dans</td>\n",
       "      <td>la</td>\n",
       "      <td>ligne</td>\n",
       "      <td>des</td>\n",
       "      <td>positions</td>\n",
       "      <td>que</td>\n",
       "      <td>notre</td>\n",
       "      <td>Parlement</td>\n",
       "      <td>a</td>\n",
       "      <td>toujours</td>\n",
       "      <td>adoptées.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1      2     3  4     5     6   7      8    9          10   11  \\\n",
       "Text  C'est  en  effet  tout  à  fait  dans  la  ligne  des  positions  que   \n",
       "\n",
       "         12         13 14        15         16  \n",
       "Text  notre  Parlement  a  toujours  adoptées.  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = french.split()\n",
    "show_tokens(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <td>C'est</td>\n",
       "      <td>en</td>\n",
       "      <td>effet</td>\n",
       "      <td>tout</td>\n",
       "      <td>à</td>\n",
       "      <td>fait</td>\n",
       "      <td>dans</td>\n",
       "      <td>la</td>\n",
       "      <td>ligne</td>\n",
       "      <td>des</td>\n",
       "      <td>positions</td>\n",
       "      <td>que</td>\n",
       "      <td>notre</td>\n",
       "      <td>Parlement</td>\n",
       "      <td>a</td>\n",
       "      <td>toujours</td>\n",
       "      <td>adoptées</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1      2     3  4     5     6   7      8    9          10   11  \\\n",
       "Text  C'est  en  effet  tout  à  fait  dans  la  ligne  des  positions  que   \n",
       "\n",
       "         12         13 14        15        16 17  \n",
       "Text  notre  Parlement  a  toujours  adoptées  .  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(french, language='french')\n",
    "show_tokens(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lemmatization](./slides/lemmas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <td>is</td>\n",
       "      <td>made</td>\n",
       "      <td>ingredients</td>\n",
       "      <td>is</td>\n",
       "      <td>baked</td>\n",
       "      <td>In</td>\n",
       "      <td>their</td>\n",
       "      <td>oldest</td>\n",
       "      <td>forms</td>\n",
       "      <td>cakes</td>\n",
       "      <td>were</td>\n",
       "      <td>modifications</td>\n",
       "      <td>cakes</td>\n",
       "      <td>preparations</td>\n",
       "      <td>features</td>\n",
       "      <td>desserts</td>\n",
       "      <td>pastries</td>\n",
       "      <td>meringues</td>\n",
       "      <td>custards</td>\n",
       "      <td>pies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmas</th>\n",
       "      <td>be</td>\n",
       "      <td>make</td>\n",
       "      <td>ingredient</td>\n",
       "      <td>be</td>\n",
       "      <td>bake</td>\n",
       "      <td>In</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>old</td>\n",
       "      <td>form</td>\n",
       "      <td>cake</td>\n",
       "      <td>be</td>\n",
       "      <td>modification</td>\n",
       "      <td>cake</td>\n",
       "      <td>preparation</td>\n",
       "      <td>feature</td>\n",
       "      <td>dessert</td>\n",
       "      <td>pastry</td>\n",
       "      <td>meringue</td>\n",
       "      <td>custard</td>\n",
       "      <td>pie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2   3      4   5       6       7      8      9   \\\n",
       "Text    is  made  ingredients  is  baked  In   their  oldest  forms  cakes   \n",
       "Lemmas  be  make   ingredient  be   bake  In  -PRON-     old   form   cake   \n",
       "\n",
       "          10             11     12            13        14        15  \\\n",
       "Text    were  modifications  cakes  preparations  features  desserts   \n",
       "Lemmas    be   modification   cake   preparation   feature   dessert   \n",
       "\n",
       "              16         17        18    19  \n",
       "Text    pastries  meringues  custards  pies  \n",
       "Lemmas    pastry   meringue   custard   pie  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(cake_wikipedia)\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Uses nlp pipeline from spacy to obtain linguistic features\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "doc = nlp(\"\".join(cake_wikipedia))\n",
    "allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "\n",
    "# Get lemmas\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "# Here we are making a list of original tokens and a list of stemmed tokens for only the tokens that changed after stemming\n",
    "lemmas_diff = [lemma for token, lemma in zip(tokens, lemmas) if token.lower() != lemma]\n",
    "og = [token for token, lemma in zip(tokens, lemmas) if token.lower() != lemma]\n",
    "\n",
    "# Show table\n",
    "show_lemmas(og, lemmas_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import PorterStemmer\n",
    "\n",
    "# Define a module that will stem the text for us\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Use the stemmer on our text\n",
    "stemmed = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "\n",
    "# Here we are making a list of original tokens and a list of stemmed tokens for only the tokens that changed after stemming\n",
    "og = [token for token, stem in zip(tokens, stemmed) if token.lower() != stem]\n",
    "stemmed_diff = [stem for token, stem in zip(tokens, stemmed) if token.lower() != stem]\n",
    "\n",
    "# Put stemmed data and text in a dataframe so we can output a table\n",
    "data = {'Stems': stemmed_diff, 'Text':og}\n",
    "df = pd.DataFrame(data, columns = ['Text', 'Stems'])\n",
    "\n",
    "# Show table\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Cake\n",
    "cake_wikipedia = 'Cake is a form of sweet food made from flour, sugar, and other ingredients, that is usually baked. In their oldest forms, cakes were modifications of bread, but cakes now cover a wide range of preparations that can be simple or elaborate, and that share features with other desserts such as pastries, meringues, custards, and pies.'\n",
    "\n",
    "# Uses nlp pipeline from spacy to obtain linguistic features\n",
    "doc = nlp(\"\".join(cake_wikipedia))\n",
    "\n",
    "data = {'Text':[token.text for token in doc], 'Lemma':[token.lemma_ for token in doc], 'Part-of-speech':[token.pos_ for token in doc], 'Dependency':[token.dep_ for token in doc], 'Shape':[token.shape_ for token in doc], 'Is Alpha':[token.is_alpha for token in doc], 'Stopword':[token.is_stop for token in doc]}\n",
    "df = pd.DataFrame (data, columns = ['Text', 'Part-of-speech'])\n",
    "\n",
    "\n",
    "df.T # show data (T means transpose, excluding the T is fine too)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame (data, columns = ['Text', 'Stopword'])\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = df.loc[df['Stopword'] == True]\n",
    "stopwords.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. https://www.nltk.org/api/nltk.tokenize.html\n",
    "2. https://www.nltk.org/_modules/nltk/tokenize/sonority_sequencing.html#SyllableTokenizer\n",
    "3. https://spacy.io/api/lemmatizer\n",
    "4. https://spacy.io/usage/linguistic-features\n",
    "5. https://universaldependencies.org/docs/u/pos/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
